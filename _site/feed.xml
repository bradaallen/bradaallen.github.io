<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.8.5">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2020-04-06T15:59:54-07:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Perpetually Learning</title><subtitle>Brad Allen's personal blog. I love building things (and learning how to build new things). Preferably those that scale. Keywords: Product Management, Data Science, Data Engineering, Python, Stanford, Stanford GSB, Penn State, Pennsylvania, TFA, Teach For America, Bain, Embrace, Aclima, Peloton Technology, Mechatronics, C+
</subtitle><entry><title type="html">Moving hosting from AWS to Github.</title><link href="http://localhost:4000/moving-to-github/" rel="alternate" type="text/html" title="Moving hosting from AWS to Github." /><published>2020-02-14T00:00:00-08:00</published><updated>2020-02-14T00:00:00-08:00</updated><id>http://localhost:4000/moving-to-github</id><content type="html" xml:base="http://localhost:4000/moving-to-github/">&lt;p&gt;&lt;em&gt;This article was written in 2017 during my time at SVDS. The article was first published on the &lt;a href=&quot;https://www.svds.com/customer-journey-set-success/&quot;&gt;SVDS Blog&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;In the &lt;a href=&quot;https://bradaallen.github.io/customer-journey-success-part-1/&quot;&gt;introductory post&lt;/a&gt;, we walked through some examples of how SVDS has seen data capabilities determine the success of customer journey initiatives for our clients. In this post, we offer guidance on the data-related initiatives that you can start today to begin fostering closer ties with your customers—regardless of where you currently are in your specific state of development.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;GH Pages:1. Use WSL, don’t mess with the devkits: https://kiazhi.github.io/blog/Working-with-Jekyll-and-Ruby-on-Windows-for-GitHub-Pages/#getting-started-with-jekyll-on-windows-10-using-windows-subsystem-for-linux&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Use rbenv, don’t mess with bare installations: https://brainwipe.github.io/jekyll/hyde/ubuntu/2017/05/16/pulling-jekyll-teeth/&lt;/li&gt;
  &lt;li&gt;Make sure you are using the gh-pages dependencies for Ruby and Jekyll: https://pages.github.com/versions/* if you had other versions pre-installed, make sure you are loading from rbenv (eg, the shims in ruby and jekyll)&lt;/li&gt;
  &lt;li&gt;Pick your theme; I like minimal mistakes: https://mmistakes.github.io/minimal-mistakes/docs/quick-start-guide/&lt;/li&gt;
  &lt;li&gt;Follow this site for then creating your GH repo, testing locally, etc: https://help.github.com/en/github/working-with-github-pages/creating-a-github-pages-site-with-jekyll&lt;/li&gt;
  &lt;li&gt;Set up a custom domain, if desired: https://help.github.com/en/github/working-with-github-pages/configuring-a-custom-domain-for-your-github-pages-site
Don’t forget the ~/.bashrc and . in jekyll new! rbenv init -, etc.
https://bryancshepherd.com/data-science/setting-bluehost-dns-github-jekyll-blog/  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;https://help.github.com/en/github/working-with-github-pages/configuring-a-custom-domain-for-your-github-pages-site 
https://help.github.com/en/github/working-with-github-pages/managing-a-custom-domain-for-your-github-pages-site
https://medium.com/@kimcodes/setting-up-a-web-page-with-github-pages-f77d45573ab2&lt;/p&gt;</content><author><name></name></author><summary type="html">Quick notes on setting up a gh-pages blog using Windows 10.</summary></entry><entry><title type="html">Agile Data Science: Don’t use the ‘D’ word.</title><link href="http://localhost:4000/developing-agile-data-scientists/" rel="alternate" type="text/html" title="Agile Data Science: Don't use the 'D' word." /><published>2019-06-07T00:00:00-07:00</published><updated>2019-06-07T00:00:00-07:00</updated><id>http://localhost:4000/developing-agile-data-scientists</id><content type="html" xml:base="http://localhost:4000/developing-agile-data-scientists/">&lt;p&gt;Even if your company has &lt;a href=&quot;https://multithreaded.stitchfix.com/blog/2019/03/11/FullStackDS-Generalists/&quot;&gt;full stack data scientists&lt;/a&gt;, data science is still ultimately a team sport. There are business stakeholders, product managers, designers, members of the infrastructure team - all of whom may have input, questions, and dependencies on the data scientist’s work. Each of these individual members likely have different interests, experiences, responsibilities, and patterns for problem solving.&lt;/p&gt;

&lt;p&gt;This diversity in perspective can be an asset, when harnessed effectively. However, if not actively managed, these perspectives can also be a huge source of miscommunication, misalignment, lack of trust, and frustration. Acknowledging this, I discourage the word “done” from my projects. Far too often, the phrase “it’s done” is accepted - when a quick review between the two parties will reveal different expectations about what “done” is supposed to mean. For example, if your data scientist says, “the model is done / ready,” do they mean:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The code accurately describes the problem, and is written purely in scripts, or&lt;/li&gt;
  &lt;li&gt;The code is functional and parametric, and accounts for common edge cases, or&lt;/li&gt;
  &lt;li&gt;The code documented and tested, in a way that can transfer ownership, or&lt;/li&gt;
  &lt;li&gt;The code is schedulable and optimized, in a way that can run in production&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Depending on where the project is in development - any of these answers could be sufficient. The challenge is when differences exist between how the two parties interpret the message.&lt;/p&gt;

&lt;h5 id=&quot;insert-image-here&quot;&gt;&lt;strong&gt;Insert image here&lt;/strong&gt;&lt;/h5&gt;

&lt;h3 id=&quot;best-practices-on-removing-the-word-done-from-your-projects&quot;&gt;Best practices on removing the word “done” from your projects&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;Empower the end user to own the logic:&lt;/em&gt; Sometimes, business users will treat the work of the data scientist as “magic.” This serves nobody - the model is not truly a “black box.” The code that dictates the inputs, the outputs, and the algorithmic approach is all logic. Sometimes the inference for a local prediction can’t be explained directly; that is a different topic than the overall problem design. Encourage conversation.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Educate the end user on the work of model building and management:&lt;/em&gt; There is &lt;a href=&quot;https://www.oreilly.com/radar/lessons-learned-turning-machine-learning-models-into-real-products-and-services/&quot;&gt;a lot of work&lt;/a&gt; to put models into production, and to maintain them once there - for example, with regard to drift, retraining, training/serving skew, security, maintenance, etc. End users should know they are investing in developing a system; the model is an artifact, not an end product, of that system.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Foster a learning culture and growth mindsets:&lt;/em&gt; Most parties working on data science projects are on a learning journey together. There is a significant amount that is “new” - most data scientists learn through apprenticeship – which can create challenges for how to communicate effectively. Simply acknowledging this can make an important difference.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Clearly articulate the tradeoffs with “good enough analysis”:&lt;/em&gt; In the data science workflow, it is easy to get stuck in a variety of local optima. For example, repeatedly asking for ad hoc analyses may give a greater intuition for the problem, while never giving the data scientist the time to professionalize her code. On the other hand, pushing for automation of a system may lead to too narrowly specifying the problem, eroding potential value. With software, there are real tradeoffs between flexibility and automation - and it is important to consider the appropriate balance for the system being defined.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;When considering “done”, a large risk present in a “good enough analysis” culture is the potential to create technical debt. Technical debt often goes unrecognized until it is too late, &lt;a href=&quot;https://martinfowler.com/articles/is-quality-worth-cost.html&quot;&gt;creating unacknowledged costs&lt;/a&gt; that will eventually need to be paid down. Even with a high prevalence of ad hoc work, it is not an excuse for running an “unclean” process. Below, please find a few recommendations to “keep things clean.”&lt;/p&gt;

&lt;h5 id=&quot;tips-for-cleanliness-in-development&quot;&gt;&lt;em&gt;Tips for cleanliness in development:&lt;/em&gt;&lt;/h5&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;Use &lt;a href=&quot;https://www.scaledagileframework.com/spikes/&quot;&gt;code spikes&lt;/a&gt;:&lt;/em&gt; Code spikes are a term from XP Programming that refer to code used to understand a problem rather than develop working code. For data science, I treat EDA as the same - and keep it out of /src within the codebase.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Enforce a good PR process:&lt;/em&gt; Google has a &lt;a href=&quot;https://google.github.io/eng-practices/review/reviewer/&quot;&gt;wonderful guide for code reviewers&lt;/a&gt;. Key quote for me is, “Don’t accept PRs that degrade the code health of the system. Most systems become complex through many small changes that add up, so it’s important to prevent even small complexities in new changes.”&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Refactor and redesign as necessary:&lt;/em&gt; Clean code really pays off, and one should restructure the codebase as the problem definition changes. Here, it’s helpful to think about Martin Fowler’s &lt;a href=&quot;https://martinfowler.com/bliki/Yagni.html&quot;&gt;YAGNI&lt;/a&gt; and &lt;a href=&quot;https://softwareengineering.stackexchange.com/questions/197363/reasoning-to-wait-until-third-time-in-the-rule-of-three&quot;&gt;Rule of Three&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;tips-for-cleanliness-in-sprint-planning&quot;&gt;&lt;em&gt;Tips for cleanliness in sprint planning:&lt;/em&gt;&lt;/h5&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;Ensure Sprint Goals are output driven:&lt;/em&gt; Writing Sprint Goals are a bit of an art, needing to be both ambitious and achievable. As data scientists practice goal setting, watch out for task-oriented outcomes that make acceptance criteria less valuable and can lead to reduced productivity.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Limit User Stories to 1-2 story points:&lt;/em&gt; Remember that story points are used to size work during sprints. They aren’t a tool to measure a developer’s productivity, and should not shouldn’t bleed across sprints.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Create viable “Plan Bs”:&lt;/em&gt; Creating options is what makes Agile work work well. When building out “Agile tests” (&lt;a href=&quot;https://bradaallen.github.io/data-science-and-agile/&quot;&gt;prior post here&lt;/a&gt;), it is important to have credible alternatives for a path forward. Otherwise, the team won’t be managing risk - they’ll be rationalizing themselves towards a predefined outcome.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;good-luck&quot;&gt;Good luck!&lt;/h3&gt;

&lt;p&gt;Hopefully after reading this, you’ll agree to the danger of using the word “done” in cross-functional teams. Fortunately, with awareness, there are many things that teams can do - in terms of both culture and process - that foster innovation and improve the likelihood of success in data science initiatives.&lt;/p&gt;</content><author><name></name></author><summary type="html">Never say you're 'done'!</summary></entry><entry><title type="html">Data Science needs Agile and Product Management.</title><link href="http://localhost:4000/data-science-and-agile/" rel="alternate" type="text/html" title="Data Science needs Agile and Product Management." /><published>2019-04-18T00:00:00-07:00</published><updated>2019-04-18T00:00:00-07:00</updated><id>http://localhost:4000/data-science-and-agile</id><content type="html" xml:base="http://localhost:4000/data-science-and-agile/">&lt;p&gt;Over the last 5 years, I have led directly or been involved in a number of enterprise projects to introduce or expand the use of machine learning. As a Product Manager turned Data Scientist, I have found time and time again that many concepts in Product Management and Agile development help de-risk and enhance the overall effectiveness of ML solutions.&lt;/p&gt;

&lt;p&gt;In this article, I’ll highlight two key concepts - one from Agile and one from Product Management - and explain how they help build sustainable, reproducible ML systems.&lt;/p&gt;

&lt;h3 id=&quot;1-agile-planning-is-about-managing-uncertainty---you-are-trading-resources-eg-time-for-information-data-science-explorations-adopt-this-mode-of-thinking-well&quot;&gt;1. Agile planning is about managing uncertainty - you are trading resources (eg, time) for information. Data science explorations adopt this mode of thinking well.&lt;/h3&gt;

&lt;p&gt;Acknowledging uncertainty is the key differentiator from an Agile and a waterfall process. The only reason I might need to adjust my backlog or iterate my sprint plans is due to the fact that my original plan could be wrong. Things &lt;strong&gt;where being wrong hurts the most&lt;/strong&gt; should be (1) broken down into tests that (2) generate information that (3) allow for decision-making under greater certainty.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;“If it hurts, do it more frequently, and bring the pain forward.” - Jez Humble&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;In my projects, we call this aspect of project design “bringing the pain forward.” This is a concept from Jez Humble’s book on &lt;a href=&quot;https://www.amazon.com/Continuous-Delivery-Deployment-Automation-Addison-Wesley/dp/0321601912&quot;&gt;Continuous Delivery&lt;/a&gt;. His book focuses on automating deployment pipelines (testing, environment management, builds, etc.) to allow for more frequent pushes to production. However, the concept translates to more general risk management as well.&lt;/p&gt;

&lt;p&gt;A primary goal is to eradicate &lt;a href=&quot;https://landing.google.com/sre/sre-book/chapters/eliminating-toil/&quot;&gt;“toil”&lt;/a&gt; - work that doesn’t make a meaningful contribution to the final product. Agile planning for ML models and applications follows a similar logic - seek to eradicate incorrect lines of inquiry, model choices, UI, and technical design as quickly as possible.&lt;/p&gt;

&lt;p&gt;Aspects of the plan that are not tested are assumptions. Erroneous assumptions can be very dangerous. If I assume a fact without designing a test, I am propagating the risk that I could be wrong “throughout” the project.&lt;/p&gt;

&lt;p&gt;Even benign assumptions can kill the value proposition of a solution, so it’s important to treat them with respect. For example:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;You do a small scale POC on one country’s transaction data using pandas or R. You know that scaling may require a centralized architecture and a distributed system, but you don’t have this discussion until you’ve proven your toy model’s efficacy. In discussing next steps, it becomes apparent your “value” is theoretical - the technical resources do not exist.&lt;/li&gt;
  &lt;li&gt;You are working to optimize the pricing of in-store goods. Designing an A/B test is difficult - you have a policy of consistent promotions (eg, no holdout) within a state or country to manage against &lt;a href=&quot;https://risnews.com/promotional-pricing-right-side-law&quot;&gt;complicated promotional pricing regulations&lt;/a&gt;. You attempt to &lt;a href=&quot;https://arxiv.org/pdf/1610.07748.pdf&quot;&gt;design a difference-in-differences or synthetic control method&lt;/a&gt; to prove incrementality, but the business sponsor dismisses it as theoretical. You have a conviction you’ve created value, but challenges in proving it.&lt;/li&gt;
  &lt;li&gt;You are working on a classification problem, e.g., churn. The business user has sold a UI in which every customer has accurate probability predictions and clear rationale supporting each customer’s prediction. However, &lt;a href=&quot;https://www.svds.com/learning-imbalanced-classes/&quot;&gt;low incidence rates (~1%) make probability calibration a challenge&lt;/a&gt;, and the range and nature of churn reasons makes &lt;a href=&quot;https://christophm.github.io/interpretable-ml-book/shap.html&quot;&gt;feature engineering for useful SHAP values&lt;/a&gt; costly and difficult. Had you been involved earlier, you would focus on ranking/discrimination and decoupling rationale from prediction, if possible.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;At the beginning of a ML exercise, make a list of everything that can go wrong - and use that as a starting point for your planning!&lt;/p&gt;

&lt;h3 id=&quot;2-data-science-plans-and-assumptions-are-best-managed-when-framed-around-a-set-of-product-and-technical-requirements&quot;&gt;2. Data science plans and assumptions are best managed when framed around a set of product and technical requirements.&lt;/h3&gt;

&lt;p&gt;Notice above that I mentioned Agile tests are for &lt;em&gt;“where being wrong matters most.”&lt;/em&gt; Experience and judgement really can make the difference between a successful project that completes on time and something that never quite works. Part of leading successful teams requires &lt;a href=&quot;https://blog.getdbt.com/4-questions-to-help-you-more-accurately-scope-analytics-engineering-projects/&quot;&gt;building reserves of trust&lt;/a&gt; with your team, your partners, and stakeholders.&lt;/p&gt;

&lt;p&gt;A good way to build trust is to give a clear conception of the end solution, with a draft set of product and technical requirements. It should be clear that these requirements are assumptions and subject to revision. It is helpful to communicate which requirements have greater uncertainty, and their associated tests in the plan.&lt;/p&gt;

&lt;p&gt;For example, at the beginning of a model and/or application’s development, I may not know:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Any &lt;strong&gt;required changes to operational processes&lt;/strong&gt; necessary for adoption (and the associated resistance to change)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Business constraints&lt;/strong&gt; that shape the necessary inputs/outputs - for example, pricing ladders constrain price outcomes, data loads/availability can affect scoring cadences&lt;/li&gt;
  &lt;li&gt;The &lt;strong&gt;right form factor&lt;/strong&gt; that will ensure a tool is used&lt;/li&gt;
  &lt;li&gt;The &lt;strong&gt;preferred business metrics&lt;/strong&gt; for measurement&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;By having a solution-mindset, and by trying to define clear product and technical requirements, I can then build slices of functionality that allow me to iterate towards a final solution.&lt;/p&gt;

&lt;p&gt;A useful mental model for how to decompose a problem is shown by the &lt;a href=&quot;https://www.hackster.io/news/starting-with-one-1f0ab62cbed4&quot;&gt;“looks like” vs. “works like”&lt;/a&gt; approach to prototyping. In this approach, the UI/UX of a solution (the “looks like”) and its core functionality (the “works like”) can be developed separately and in parallel. As feedback about each component is collected, it may influence the requirements of the other component. For example, technical limitations may impact requirements for the user experience, and revisions of the user workflow may change the roadmap/priorities of the different technical features.&lt;/p&gt;

&lt;p&gt;Each component of the overall solution can then be further decomposed into basic components, with a priority for collecting quick feedback. This follows John Gall’s famous &lt;a href=&quot;https://quotesondesign.com/john-gall/&quot;&gt;quote&lt;/a&gt;: &lt;em&gt;“A complex system that works is invariably found to have evolved from a simple system that worked.”&lt;/em&gt;&lt;/p&gt;

&lt;h4 id=&quot;a-few-recommendations-for-building-out-your-ml-solution&quot;&gt;A few recommendations for building out your ML solution:&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;For the solution design, the first simple system should be a &lt;a href=&quot;https://codeclimate.com/blog/kickstart-your-next-project-with-a-walking-skeleton/&quot;&gt;“walking skeleton.”&lt;/a&gt; Having a functional end-to-end pipeline with limited functionality will ferret out any integration issues early, and can surface necessary storage and processing patterns.&lt;/li&gt;
  &lt;li&gt;For the model design, the first simple system should be the quickest MVP that creates a baseline prediction. &lt;a href=&quot;https://techdevguide.withgoogle.com/resources/rules-of-ml/&quot;&gt;Google’s Rules of ML&lt;/a&gt; suggest using ML only after heuristics become too complex. This logic should extend to ML solutions as well, starting with straightforward implementations that become increasingly sophisticated (eg, start with classical time-series methods for forecasting before testing nonlinear approaches).&lt;/li&gt;
  &lt;li&gt;For interaction design, design thinking approaches should guide the first simple system:
    &lt;ul&gt;
      &lt;li&gt;Generate options for yourself - &lt;a href=&quot;https://www.teachthought.com/critical-thinking/3-modes-of-thought-divergent-convergent-thinking/&quot;&gt;get comfortable exploring ideas using divergent thinking&lt;/a&gt;. Great solutions often steal components from multiple good ideas.&lt;/li&gt;
      &lt;li&gt;Find ways to &lt;a href=&quot;https://www.wired.com/2014/02/stanford-class-taught-two-normal-guys-star-designers/&quot;&gt;collect user behavior&lt;/a&gt; - information through engagement can often be of higher quality than basic market or user research.&lt;/li&gt;
      &lt;li&gt;Get engagement through visual tools (eg, &lt;a href=&quot;https://www.experienceux.co.uk/faqs/what-is-wireframing/&quot;&gt;wireframing&lt;/a&gt;, excel mockups) - take time to listen and pay attention to points of friction or counterintuitive (to use) usage&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;applied-ml---managing-the-high-risk-high-reward-tradeoff&quot;&gt;Applied ML - managing the “high risk, high reward” tradeoff.&lt;/h3&gt;

&lt;p&gt;ML systems are known for the tremendous value they can create, as well as their potential for &lt;a href=&quot;https://research.google/pubs/pub43146/&quot;&gt;“high interest” technical debt&lt;/a&gt;, drift, biased predictions, etc. These challenges are often coupled with the need to educate business users on how to interact with such systems, their role and responsibilities, and managing expectations about what can vs. what cannot be done.&lt;/p&gt;

&lt;p&gt;Proven software development approaches for doing this well - particularly Agile and Product Management principles - can create trust and accelerate the adoption of these tools and capabilities.&lt;/p&gt;</content><author><name></name></author><summary type="html">Or, 'how to manage expectations under uncertainty.'</summary></entry><entry><title type="html">Review of recent trends in Data Science.</title><link href="http://localhost:4000/pulse-on-data-science-trends/" rel="alternate" type="text/html" title="Review of recent trends in Data Science." /><published>2019-02-21T00:00:00-08:00</published><updated>2019-02-21T00:00:00-08:00</updated><id>http://localhost:4000/pulse-on-data-science-trends</id><content type="html" xml:base="http://localhost:4000/pulse-on-data-science-trends/">&lt;p&gt;&lt;em&gt;Every week, I spend ~5h reading my favorite newsletters on data science (eg, Data Science Roundup, Data Elixir, Jack Clark, Daniel Meissner). My most recent project prevented me from catching up on these articles for a few months - so I took a few days to catch up and synthesize what I had been seeing. That summary can be found below.&lt;/em&gt;&lt;/p&gt;

&lt;h3 id=&quot;key-takeaways&quot;&gt;Key takeaways&lt;/h3&gt;

&lt;p&gt;Most of the interesting articles were saying the same things:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Role definition is still happening, but there is alignment that hybrid models in business are useful&lt;/li&gt;
  &lt;li&gt;Businesses are continuing to invest in these initiatives, more understanding that it is not “magic”&lt;/li&gt;
  &lt;li&gt;Platforms and cloud tooling continue to enforce the imperative for DS to be able to own models “end to end” - the DS needs to write clean code and launch to production; can be on platforms built by SWE &amp;amp; DE&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;I didn’t see very much interesting on actual techniques (&lt;a href=&quot;https://www.basilica.ai/blog/the-unreasonable-effectiveness-of-deep-feature-extraction/&quot;&gt;besides a very interesting post on transfer learning as deep feature extraction&lt;/a&gt;), but have shared some below. Lots of talk on ethics, some talk on RL and all of the NLP stuff (Bert &amp;amp; ELMo, etc – great summary of this as an ImageNet moment &lt;a href=&quot;https://thegradient.pub/nlp-imagenet&quot;&gt;here&lt;/a&gt;).&lt;/p&gt;

&lt;h3 id=&quot;role-of-a-data-engineer&quot;&gt;Role of a Data Engineer&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;https://blog.fishtownanalytics.com/does-my-startup-data-team-need-a-data-engineer-b6f4d68d7da9&quot;&gt;Do I need a data engineer?&lt;/a&gt; Here is a second supporting article, &lt;a href=&quot;https://www.locallyoptimistic.com/post/analytics-engineer/&quot;&gt;distinguishing between DE and an “Analytics Engineer.”&lt;/a&gt; Suggests using stitch, fivetran, dbt as data engineering tools in lieu of Airflow. Natural migration (in startups at least) is to do PoCs, early builds on Airflow and then migrate to a more resilient tool like those listed. Super critical role (and primary responsibilities of our principal data engineers on a project), should be responsible for:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Managing and optimizing core data infrastructure,&lt;/li&gt;
  &lt;li&gt;Building and maintaining custom ingestion pipelines,&lt;/li&gt;
  &lt;li&gt;Supporting data team resources with design and performance optimization (think 1 DE for 3 DS) and&lt;/li&gt;
  &lt;li&gt;Building non-SQL transformation pipelines (PySpark ETL (maybe), geo enrichment)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I thought the idea of removing Airflow for SQL transformations was an interesting trend. I haven’t ever used the three “pipeline-as-a-service” products. For MDS, the above responsibilities were good to have for our primary data engineer (Cloves), with a separate, proper SW developer as the code master. I think I would almost always use someone from Toptal for this 2nd role.&lt;/p&gt;

&lt;h3 id=&quot;more-on-role-definition-the-kinds-of-a-data-scientist&quot;&gt;More on role definition. &lt;a href=&quot;https://hbr.org/2018/11/the-kinds-of-data-scientist&quot;&gt;“The Kinds of a Data Scientist.”&lt;/a&gt;&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;The VP, DS of Instacart &lt;a href=&quot;https://firstround.com/review/doing-data-science-right-your-most-common-questions-answered/&quot;&gt;split the key types of work&lt;/a&gt; into “Decision Science” vs. “Data Products” to identify skills required. I thought the Decision Science example was pretty interesting.&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;*At LinkedIn, the executive team used decision science to make a critical business decision about the visibility of member profiles in search results. Historically, only paid users could see full profiles for everyone in their extended (third-degree) network. The visibility rules were complex, and LinkedIn wanted to simplify them — but not in a way that would undermine its revenue. The stakes were enormous.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;The proposed visibility model was a monthly use limit for unpaid users, with a cut-off based on usage. LinkedIn’s decision scientists simulated the effects of this change, using historical behavior to predict the impact on revenue and engagement. The analysis had to extrapolate past behavior on one model to forecast behavior on a radically different one. Nonetheless, the analysis was sufficient to move forward.*&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.locallyoptimistic.com/post/code-as-configuration/&quot;&gt;“Code as Configuration”&lt;/a&gt;. Article written by an experienced DS outlining how DS &amp;amp; SWE/DE should think about working together.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;project-management&quot;&gt;Project management.&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://hackernoon.com/rethinking-fast-and-slow-in-data-science-b2ce18d5b054&quot;&gt;Doing Agile in Data Science&lt;/a&gt;. Google. Particular focus on taking the scientific method and breaking it down into “less rigorous hypotheses” that can be (1) time bound and (2) better inform the LT hypotheses you want to prove or disprove in an experiment.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://simplystatistics.org/2018/09/14/divergent-and-convergent-phases-of-data-analysis/&quot;&gt;Divergent and convergent thinking in data analysis&lt;/a&gt;. An okay article, on a great concept. With the article above, how do we coach projects to (1) generate good hypotheses with the associated code “spikes”, (2) then fit that into design patterns, etc. that allow us to grow code safely? This can also be very useful for identifying product/project/pilot requirements with business users. I’ve received feedback in projects that “divergent thinking is very uncomfortable” but the decisions it can lead to are almost always of higher value than what a convergent path would provide.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=qCKj_K5RNfY&quot;&gt;Design for Continuous Experimentation&lt;/a&gt;. Etsy. How Etsy learned to build stage gates into their product development process and use A/B tests to enable stage gate decisions (!!!) I liked how the Principal Engineer framed the way they used their learning from things that did not go well for future projects&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://medium.com/coursera-engineering/should-engineering-managers-write-code-wrong-question-ec5fc54d3903&quot;&gt;How much should managers code? Wrong question. Where to write code?&lt;/a&gt; Coursera. Emphasizes being invested in small bug fixes, code reviews, and JIRA to develop a manager’s empathy for the team’s work and foster better outcomes.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://blog.insightdatascience.com/an-introduction-to-the-data-product-management-landscape-ef930afe6de5&quot;&gt;The State of Data Product Management Roles&lt;/a&gt;. Insight Data Science. Highlights 5 domain areas: Infrastructure, Analytics, Applied ML/AI, Platforms, Standardization &amp;amp; Discovery. Note that Analytics and Applied AI/ML roles map well to the two different “kinds of data scientists” outlined above, and the other 3 are DevOps-y in nature.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;experimentation&quot;&gt;Experimentation.&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://hookedondata.org/guidelines-for-ab-testing&quot;&gt;Guidelines for AB Testing at Etsy&lt;/a&gt;. Advocates for frequentists methods and to establish measurement up front first. Great anecdote on how more measurement up front changed their delivery process for new features. Many, many links for follow on reads.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://varianceexplained.org/r/bayesian-ab-testing/&quot;&gt;Is Bayesian Testing Immune to Peeking? Not Exactly&lt;/a&gt;. Stack Overflow (the company). Less about the Bayesian approach, I thought this was a great way of showing how to use simulation to trust the data behind your decisions (and how p-values can change over time). I fell into a small rabbit hole reading about AB testing from these articles; a theme for me was many different teams using simulation to “shore up” questions around experiment design.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://eng.uber.com/analyzing-experiment-outcomes/&quot;&gt;Analyzing Experiment Outcomes: Beyond ATEs&lt;/a&gt;. Uber. Walks through a metric called Quantile Treatment Effect (QTE) that allows for understanding heterogeneity in treatment effects. Cool.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://medium.com/airbnb-engineering/experimentation-measurement-for-search-engine-optimization-b64136629760&quot;&gt;Experimentation &amp;amp; Measurement for SEO&lt;/a&gt;. Airbnb. Useful case study of when to use differences-in-differences and some of the idiosyncrasies to account for.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;data--infrastructure-engineering&quot;&gt;Data / infrastructure engineering.&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://medium.com/airbnb-engineering/capturing-data-evolution-in-a-service-oriented-architecture-72f7c643ee6f&quot;&gt;Capturing data evolution in a SOA&lt;/a&gt;. Airbnb&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://multithreaded.stitchfix.com/blog/2018/09/05/datahighway/&quot;&gt;Putting the power of Kafka into the hands of data scientists&lt;/a&gt;. Stitch Fix&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.oreilly.com/ideas/the-future-of-data-warehousing&quot;&gt;Future of Data Warehousing&lt;/a&gt;. Cloudera/PNC. Short, 5 min video outlining some challenges standing up a distributed system – seen these challenges at all projects and would expect our DE to work with and help the client set up these processes.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;techniques-tools--interesting-reads&quot;&gt;Techniques, Tools, &amp;amp; Interesting reads.&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://multithreaded.stitchfix.com/blog/2018/11/08/bandits/&quot;&gt;Contextual bandits for content outreach&lt;/a&gt;. Stitch Fix&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://robatwilliams.github.io/decent-code/&quot;&gt;How to write clean code and conduct code reviews&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://exxeta.github.io/2018/10/forecast_sales_in_retail&quot;&gt;Forecast sales in retail&lt;/a&gt;. A good reference for establishing a baseline and packages/methods&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://towardsdatascience.com/3-facts-about-time-series-forecasting-that-surprise-experienced-machine-learning-practitioners-69c18ee89387&quot;&gt;3 facts about time-series analyses that can surprise ML people&lt;/a&gt;. (eg, “The uncertainty of the forecast is just as important as, or even more so, than the forecast itself.”)&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://machinelearningmastery.com/time-series-forecasting-methods-in-python-cheat-sheet/&quot;&gt;11 classical time series forecasting methods in Python&lt;/a&gt;. Related: &lt;a href=&quot;https://eng.uber.com/forecasting-introduction/&quot;&gt;Forecasting at Uber&lt;/a&gt;. Interesting to see Uber’s built-in backtesting system.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://rise.cs.berkeley.edu/blog/a-short-history-of-prediction-serving-systems/&quot;&gt;A short history of prediction serving systems&lt;/a&gt;. RISE Lab. Discusses the architecture of RISE’s Clipper system, and has an interesting paper from LinkedIn on managing the tradeoff between accuracy and serving latency.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/nteract/papermill#usage&quot;&gt;Papermill&lt;/a&gt;. Parametric, scheduled Jupyter notebooks with the option for aggregate summaries. Used a lot at Netflix.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://better.engineering/convoys/&quot;&gt;Convoys&lt;/a&gt;. PyPI package for time-lagged conversion rates (eg, telco churn..)&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><summary type="html">Topics: data engineering, role definition, project management, experimentation, et al.</summary></entry><entry><title type="html">Is Your Customer Journey Set Up for Success? Part II.</title><link href="http://localhost:4000/customer-journey-success-part-2/" rel="alternate" type="text/html" title="Is Your Customer Journey Set Up for Success? Part II." /><published>2018-07-10T00:00:00-07:00</published><updated>2018-07-10T00:00:00-07:00</updated><id>http://localhost:4000/customer-journey-success-part-2</id><content type="html" xml:base="http://localhost:4000/customer-journey-success-part-2/">&lt;p&gt;&lt;em&gt;This article was written in 2017 during my time at SVDS. The article was first published on the &lt;a href=&quot;https://www.svds.com/customer-journey-set-success/&quot;&gt;SVDS Blog&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;In the &lt;a href=&quot;https://bradaallen.github.io/customer-journey-success-part-1/&quot;&gt;introductory post&lt;/a&gt;, we walked through some examples of how SVDS has seen data capabilities determine the success of customer journey initiatives for our clients. In this post, we offer guidance on the data-related initiatives that you can start today to begin fostering closer ties with your customers—regardless of where you currently are in your specific state of development.&lt;/em&gt;&lt;/p&gt;

&lt;h3 id=&quot;customer-journeys-allow-for-a-holistic-experience&quot;&gt;Customer journeys allow for a holistic experience&lt;/h3&gt;

&lt;p&gt;A senior marketer’s ability to find and create valuable experiences for customers has grown dramatically in recent years. Beyond the traditional responsibilities of brand and creative management, senior marketers (such as CMOs, Brand Managers, and Product Marketing Managers) now use analytics to track customer interactions, measure the quality of engagement, and determine the effectiveness of an enormous range of different marketing tactics.&lt;/p&gt;

&lt;p&gt;Marketers often map out a &lt;a href=&quot;https://hbr.org/2015/11/competing-on-customer-journeys&quot;&gt;“customer journey”&lt;/a&gt; in order to manage successful engagements. The customer journey is the complete sum of experiences that your customers go through when interacting with your company and brand—mapping out these interactions gives you a holistic view of how customers engage with your company. While many marketers focus on developing positive interactions, a customer journey is a plan that focuses on how a series of engagements can generate momentum from awareness, to sale, to ongoing loyalty and advocacy.&lt;/p&gt;

&lt;h3 id=&quot;creating-customer-journey-opportunities-with-data&quot;&gt;Creating customer journey opportunities with data&lt;/h3&gt;

&lt;p&gt;At SVDS, we have seen leaders use data to drive more useful customer engagements—first and foremost by recognizing their need to embrace change. There is a big shift taking place, and that shift will become the new normal.&lt;/p&gt;

&lt;p&gt;You should be trying to learn quickly, and fail fast. Companies that are able make the best use of their data and infrastructure earlier than their competition are at an advantage—both with regard to increased customer loyalty and improvements in new product development.&lt;/p&gt;

&lt;p&gt;In a &lt;a href=&quot;https://bradaallen.github.io/customer-journey-success-part-1/&quot;&gt;November 2015 Harvard Business Review article&lt;/a&gt; on the customer journey, the authors stated that, “Best practitioners aim not just to improve the existing journey but to expand it, adding useful steps or features.” As mentioned in the examples earlier in this post, we have seen the same trend: clients who can harness their data to create effective customer experiences often make further investments toward developing their capabilities.&lt;/p&gt;

&lt;p&gt;There are data-related initiatives that you can begin pursuing today to develop stronger relationships with your customers. Make an honest assessment of where you stand now, and find yourself in the sections below.&lt;/p&gt;

&lt;h4 id=&quot;if-you-are-starting-from-scratch&quot;&gt;If you are starting from scratch:&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;Common Challenges&lt;/em&gt;
    &lt;ul&gt;
      &lt;li&gt;Redefining decision-making based on insights&lt;/li&gt;
      &lt;li&gt;Identifying single points of ownership&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Common Solutions&lt;/em&gt;
    &lt;ul&gt;
      &lt;li&gt;Focus on top-down buy-in. Without recognition from leadership, data initiatives will struggle to get relevance with business users and may be piecemeal efforts, diminishing the value of investment.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;if-you-are-performing-early-project-identification&quot;&gt;If you are performing early project identification:&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;Common Challenges&lt;/em&gt;
    &lt;ul&gt;
      &lt;li&gt;Mapping out customer journey initiatives&lt;/li&gt;
      &lt;li&gt;Identifying single points of ownership&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Common Solutions&lt;/em&gt;
    &lt;ul&gt;
      &lt;li&gt;Get alignment on the full picture. It is important to be able to articulate the “full view” of the customer experience as it has a large effect on decision making. For example, only tracking successful interactions would lead to very different conclusions than understanding users that “turn away.”&lt;/li&gt;
      &lt;li&gt;Plan for iteration. It often takes time to understand where your map does and does not match your customers’ realities.&lt;/li&gt;
      &lt;li&gt;Start small. Change can be incremental—look for low-hanging fruit.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;if-you-are-establishing-customer-visibility&quot;&gt;If you are establishing customer visibility:&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;Common Challenges&lt;/em&gt;
    &lt;ul&gt;
      &lt;li&gt;Data integration&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Common Solutions&lt;/em&gt;
    &lt;ul&gt;
      &lt;li&gt;Prioritize data collection in tandem with journey mapping. In instrumentation, it is important to know what behaviors you can collect directly from customers and what behaviors you have to infer based on their actions. This influences what additional data sources you include to support decisions you make for the business.&lt;/li&gt;
      &lt;li&gt;Seek to reuse and extend data services. Developing known, validated, and consistent data assets for your business increases their utility and dramatically improves trust in the developed insights across the organization.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;if-you-are-optimizing-for-growth&quot;&gt;If you are optimizing for growth:&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;Common Challenges&lt;/em&gt;
    &lt;ul&gt;
      &lt;li&gt;Personalization and automation&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Common Solutions&lt;/em&gt;
    &lt;ul&gt;
      &lt;li&gt;Enable advanced analytics. Optimize for automation to create feedback loops and self-learning capabilities that make it easy to identify and capitalize on growth opportunities.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;What steps are you taking to strengthen your customer engagement strategies through better use of data?&lt;/p&gt;</content><author><name></name></author><summary type="html">Practical recommendations for any level of sophistication.</summary></entry><entry><title type="html">Is Your Customer Journey Set Up for Success? Part I.</title><link href="http://localhost:4000/customer-journey-success-part-1/" rel="alternate" type="text/html" title="Is Your Customer Journey Set Up for Success? Part I." /><published>2018-07-03T00:00:00-07:00</published><updated>2018-07-03T00:00:00-07:00</updated><id>http://localhost:4000/customer-journey-success-part-1</id><content type="html" xml:base="http://localhost:4000/customer-journey-success-part-1/">&lt;p&gt;&lt;em&gt;This article was written in 2017 during my time at SVDS. The article was first published on the &lt;a href=&quot;https://www.svds.com/customer-journey-set-success/&quot;&gt;SVDS Blog&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;

&lt;h3 id=&quot;customer-journeys-allow-for-a-holistic-experience&quot;&gt;Customer journeys allow for a holistic experience&lt;/h3&gt;

&lt;p&gt;A senior marketer’s ability to find and create valuable experiences for customers has grown dramatically in recent years. Beyond the traditional responsibilities of brand and creative management, senior marketers (such as CMOs, Brand Managers, and Product Marketing Managers) now use analytics to track customer interactions, measure the quality of engagement, and determine the effectiveness of an enormous range of different marketing tactics.&lt;/p&gt;

&lt;p&gt;Marketers often map out a &lt;a href=&quot;https://www.forrester.com/Customer-Journey&quot;&gt;“customer journey”&lt;/a&gt; in order to manage successful engagements. The customer journey is the complete sum of experiences that your customers go through when interacting with your company and brand—mapping out these interactions gives you a holistic view of how customers engage with your company. While many marketers focus on developing positive interactions, a customer journey is a plan that focuses on how a series of engagements can generate momentum from awareness, to sale, to ongoing loyalty and advocacy.&lt;/p&gt;

&lt;p&gt;According to a &lt;a href=&quot;https://www.salesforce.com/blog/2014/11/new-report-salesforce-marketing-cloud-linkedin-state-marketing-leadership.html&quot;&gt;Salesforce report&lt;/a&gt;, nearly all senior level marketers agree that a comprehensive journey map is absolutely critical or very important to their business. At the same time, the report mentions that this map has largely been an aspiration for marketers—in part due to siloed business teams and a disjointed view of customer data, only 29% of enterprise companies would rate themselves as very effective or effective at creating a cohesive journey.&lt;/p&gt;

&lt;p&gt;Senior marketers should take the responsibility for this challenge head on; to be successful in creating a useful map, you will also need to be the leader of the technical and analytical development of their teams. You should have an intuition for how data can enhance, track, and articulate the customer experience—as this intuition creates new possibilities for the type of relationships companies can have with their customers.&lt;/p&gt;

&lt;p&gt;In this first post, we’ll walk through some examples of how we have seen data capabilities determine the success of customer journey initiatives for our clients. In &lt;a href=&quot;https://bradaallen.github.io/customer-journey-success-part-2/&quot;&gt;subsequent posts&lt;/a&gt;, we’ll also offer guidance on the data-related initiatives that you can start today to begin fostering closer ties with your customers—regardless of where you currently are in your specific state of development.&lt;/p&gt;

&lt;h3 id=&quot;what-can-your-data-do-for-you&quot;&gt;What can your data do for you?&lt;/h3&gt;

&lt;p&gt;We’ve seen data play various roles in creating strong customer engagements. Here’s a look at just a few.&lt;/p&gt;

&lt;h4 id=&quot;optimize-against-competing-outcomes-using-effectively-stitched-data-social-gaming&quot;&gt;Optimize against competing outcomes using effectively stitched data (Social Gaming)&lt;/h4&gt;

&lt;p&gt;For many businesses, legacy and heterogeneous systems are a challenge for creating an integrated customer experience—the data is often structured with a narrow lens on a specific product or domain. We worked with a social gaming company facing this challenge: they wanted to create a cohesive customer experience across all their games by extending the preferential treatment that loyal customers receive for their favorite games to new games on the platform.&lt;/p&gt;

&lt;p&gt;On a per-game basis, our client was technically sophisticated—they could build out events, correlate performance with targeted marketing strategies, and articulate the effectiveness of different campaigns. However, this sophistication fell apart at the organization-wide level. After several acquisitions and the use of third party licensing for games, the company found itself with a broken analytical architecture—each game optimized for itself, but there was a lot of opportunity in optimizing across the business. By supporting the integration of different data from different silos, the new architecture enabled the company to:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;Increase customer satisfaction by rewarding loyalty.&lt;/em&gt; By not being able to establish a single view of their customers, our client was continually losing opportunities to tailor experiences for their customers. For example, high-paying customers that had “preferred” status for certain games would return to being “unknown” when they started playing new games. By helping the client carry customer status across games, players will have greater satisfaction and loyalty.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Improve game development by understanding interaction patterns.&lt;/em&gt; Some of the most important metrics in gaming—e.g., alliances and teaming—are challenging to measure. Breaking down silos allowed the client to utilize novel sources of data, like gaming chats, to articulate a “web of influence” and its role in engagement and profitability.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;By reframing the customer journey as an experience that transcends individual games—and developing a supporting data architecture—our client was able to both develop an engine for growth and improve profitability on an individual basis, by both reducing the acquisition cost (UAC) of customers and increasing their lifetime value (LTV).&lt;/p&gt;

&lt;h4 id=&quot;redefine-your-brand-and-product-suite-with-a-more-modern-architecture-digital-entertainment&quot;&gt;Redefine your brand and product suite with a more modern architecture (Digital Entertainment)&lt;/h4&gt;

&lt;p&gt;Take a look at the data sources you’re using in your marketing efforts and you may find some unexpected insights. For example, is there untapped value in your existing customer relationships? A digital entertainment company wanted to develop a modern database architecture that would allow them to understand user consumption at both a customer and population-level—at a microsecond granularity.
Redesigning the client’s architecture to identify and articulate the customer’s consumption patterns ultimately gave the client vastly more usable data about their customers, which led to:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;New customer offerings.&lt;/em&gt; Our client used these new capabilities to develop more effective cross-selling opportunities and to develop products that provide guidance to content providers.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Improved strategic decision making.&lt;/em&gt; This view of consumption informed large strategic bets for the organization—for example, the decision to give away existing products for free in return for increased engagement.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The client had always had tremendous potential to understand customer engagement and consumption patterns—they were a portal for millions of users. However, their existing platform was limited by its underlying technology and a myopic view of the role of data. In their original product offering, the collected data was not necessarily perceived to have inherent value. We find this type of oversight to be common for marketers beginning to build analytics within their teams.&lt;/p&gt;

&lt;p&gt;Note: This concept of “instrumentation”—the process of logging and tracking customer interactions—is important when creating an engagement plan. Instrumentation creates a more nuanced understanding of what customers find valuable about your products and services. For our client, this instrumentation influenced their entire business: from feature development, to sales, to pricing, and even to marketing copy about the efficacy of their existing product suite. Instrumentation is so important, in fact, that it is something we at SVDS specifically assess when considering the &lt;a href=&quot;https://www.svds.com/understanding-your-data-maturity/&quot;&gt;data maturity of a business&lt;/a&gt;.&lt;/p&gt;

&lt;h4 id=&quot;update-back-office-processes-to-redefine-customer-expectations-national-retailer&quot;&gt;Update back-office processes to redefine customer expectations (National Retailer)&lt;/h4&gt;

&lt;p&gt;Work that begins in the marketing department often extends to influence other parts of a business. In one example, we worked with a traditional brick and mortar retail client that was in the process of developing their digital presence.&lt;/p&gt;

&lt;p&gt;As their customers began to spend more time purchasing items online, our client realized that they would need new capabilities to support new types of interactions—for example, granularity in tracking inventory. When creating its online presence, our client found itself frequently selling under-stocked items from the website, and then had to follow them up with costly gift card apologies to disappointed customers.&lt;/p&gt;

&lt;p&gt;We helped the client gain an understanding of their inventory baseline and establish a real-time view of changes in supply and demand. This allowed the business as a whole to establish new customer relationships and a leaner efficiency:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;Customer interaction with the brand.&lt;/em&gt; E-commerce has developed some great features to incent purchasing behavior—we have all experienced messages like, “There are only 3 items left in stock!” or “Order by 11:59pm Tuesday to get by Christmas.” Our client’s new modern inventory infrastructure allowed them to create similar features, increasing trust and confidence in the brand.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Reduced working capital.&lt;/em&gt; In the past, a granular level of detail—across stores, channels, and partners (e.g., third party sellers)—was not required from legacy operations. In developing a new system, our client was able to serve items that were stocked-out in their web distribution centers from stores in close proximity to the buyers. This allowed our client to reduce their buffer stock and protect against obsolescence.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For our retail client, marketing’s strategic influence and digital leadership forced growth in other parts of the business that benefited customers and improved the company’s competitive position.&lt;/p&gt;

&lt;h3 id=&quot;next-steps&quot;&gt;Next Steps&lt;/h3&gt;

&lt;p&gt;How is your company taking steps to strengthen their customer engagement strategies through better use of data?&lt;/p&gt;</content><author><name></name></author><summary type="html">Case studies from high performing transformations.</summary></entry><entry><title type="html">Data Maturity: Technology is Not Enough</title><link href="http://localhost:4000/technology-isnt-everything/" rel="alternate" type="text/html" title="Data Maturity: Technology is Not Enough" /><published>2018-05-15T00:00:00-07:00</published><updated>2018-05-15T00:00:00-07:00</updated><id>http://localhost:4000/technology-isnt-everything</id><content type="html" xml:base="http://localhost:4000/technology-isnt-everything/">&lt;p&gt;&lt;em&gt;This article was co-authored along with Scott Kurth in 2017, based on our experience at SVDS. The article was first published on the &lt;a href=&quot;https://www.svds.com/value-centered-data-maturity/&quot;&gt;SVDS Blog&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;

&lt;h3 id=&quot;success-with-data-involves-managing-strengths-and-weaknesses&quot;&gt;Success with data involves managing strengths and weaknesses&lt;/h3&gt;

&lt;p&gt;The great data rush is well and truly under way. Across virtually every industry, companies large and small are committing serious money to standing up their data infrastructure, beefing up capabilities, and hunting for the value hidden in their data—but often without a clear plan. No wonder that many of the business leaders we speak with suspect their initiatives are underperforming. The complaint we hear most frequently, regardless of industry, is that technology investments aren’t generating the expected returns.&lt;/p&gt;

&lt;p&gt;In a &lt;a href=&quot;https://www.svds.com/first-steps-strategy/&quot;&gt;previous post on data maturity&lt;/a&gt;, we discussed a company that was just embarking on a transformation: launching a new services business and building data capabilities to support that business. But what if you’re not starting from the beginning? What if you’ve already been embracing new technology, conducting pilots, and launching new analytical platforms? Recently, we were working with a Fortune 500 industrial company in the midst of developing software services to improve product R&amp;amp;D and enrich the customer experience.&lt;/p&gt;

&lt;p&gt;Their goal was to &lt;a href=&quot;https://svds.com/building-a-data-driven-culture/&quot;&gt;use data to empower decision makers&lt;/a&gt; across every part of the organization to make robust, data-driven choices. The company had great talent, technical vision, and infrastructure. &lt;strong&gt;Still, they weren’t generating the progress they would have liked at a rate they would have expected. What was wrong?&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&quot;sometimes-the-business-can-hold-good-technology-behind&quot;&gt;Sometimes, the business can hold good technology behind&lt;/h3&gt;

&lt;p&gt;Working with our client to articulate their overall data maturity shined a light on areas requiring attention to get the most of their technology investments:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;Missing links between projects and metrics:&lt;/em&gt; The initiative’s overall success was being measured by a single metric that they could only begin tracking in 2020—at the completion of the transformation. This led to significant uncertainty within project teams building new capabilities and platforms. Many teams were unsure where their analytical work fit in the big into the larger efforts and, more importantly, whether they were contributing to the overall success of the transformation.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Lack of cross-functional teams:&lt;/em&gt; The analytical infrastructure built by the engineering team was impressive, but was sorely underutilized. The data scientists had not been trained to use it and did not know how to access it. We heard from an analytics manager: “Seventy percent of my team’s time is spent on writing UDFs and Pig scripts to access data!” Creating teams that facilitated collaboration between engineers and data scientists was an opportunity for quick productivity gains with expensive talent.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Siloed business functions:&lt;/em&gt; Teams felt a lack of clear objectives that stemmed from communication and information sharing issues with other teams. For example, one team integral to product development described their view of the future as “a dusty window.” Business units on the consumption side of application development experienced very uneven usage of analytical tools. Strengthening these partnerships was crucial as the overarching project’s success relied specifically on strong analytical capabilities throughout the entire organization.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In working together, we helped the industrial company link their data and analytical capabilities with their ultimate business objectives, allowing them to create the right metrics to truly understand their progress. We helped them improve their devops capabilities and better integrate their engineering and data science teams. Collectively, this helped them break down technical and organizational siloes that were hampering progress.&lt;/p&gt;

&lt;p&gt;Understanding the uneven maturity of their capabilities across people, process, and systems gave them the answers they needed to the question on everyone’s minds: How can we see real results faster? A view of the current state of maturity along with a clear roadmap for success creates a baseline and a way to measure progress.&lt;/p&gt;</content><author><name></name></author><summary type="html">Knowing what to do with it is what matters most.</summary></entry><entry><title type="html">Understanding Your Data Maturity</title><link href="http://localhost:4000/understanding-data-maturity/" rel="alternate" type="text/html" title="Understanding Your Data Maturity" /><published>2018-05-01T00:00:00-07:00</published><updated>2018-05-01T00:00:00-07:00</updated><id>http://localhost:4000/understanding-data-maturity</id><content type="html" xml:base="http://localhost:4000/understanding-data-maturity/">&lt;p&gt;&lt;em&gt;This article was co-authored along with Scott Kurth in 2017, based on our experience at SVDS. The article was first published on the &lt;a href=&quot;https://www.svds.com/understanding-your-data-maturity/&quot;&gt;SVDS Blog&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;

&lt;h3 id=&quot;how-effective-are-you-with-your-capabilities&quot;&gt;How &lt;em&gt;effective&lt;/em&gt; are you with your capabilities?&lt;/h3&gt;

&lt;p&gt;Businesses today are experiencing rapid change, inside and outside of Silicon Valley. Even coffee isn’t immune—just last year, Starbucks crossed the threshold of &lt;a href=&quot;https://www.bloomberg.com/news/articles/2016-03-30/starbucks-takes-its-pioneering-mobile-phone-app-to-grande-level&quot;&gt;more than 20% of transactions being done in their mobile application&lt;/a&gt;. Data is the currency of &lt;a href=&quot;https://svds.com/optimizing-your-digital-strategy/&quot;&gt;digital transformation&lt;/a&gt;, and data capabilities are the battlefield influencing market share and profitability.&lt;/p&gt;

&lt;p&gt;No two situations are the same, but at SVDS we have found one truism: making a data transformation successful requires much more than simply getting the technology right. Across a variety of industries and operations, we consistently find the influence of systems and people to be deciding factors. This is one of the reasons why we developed our &lt;a href=&quot;https://svds.com/what-are-you-doing-with-your-data/&quot;&gt;Data Maturity Model&lt;/a&gt; — a tool for understanding how well your data capabilities create value for your business, across people, process, and systems.&lt;/p&gt;

&lt;h3 id=&quot;data-maturity-in-practice&quot;&gt;Data maturity in practice&lt;/h3&gt;

&lt;p&gt;Data maturity is a useful tool for measuring the progress being made against your transformation. Recently, we were working with a multi-billion dollar industrial device company that was just beginning their Internet of Things (IoT) transformation: integrating software services with their physical devices. The vision was set and small experiments were being run throughout the organization—but the real work of building had not yet begun.&lt;/p&gt;

&lt;p&gt;The company’s overarching strategy made a lot of sense—building a higher-margin services business from the key position their devices play in their customers’ workflows. We were asked to help them develop a data strategy and accompanying architecture to make that possible. Fundamentally, they needed a plan to use analytics and device data to create new services their clients would value.&lt;/p&gt;

&lt;p&gt;While this company certainly had major technology investments in its future, some of the most urgent things necessary for this transformation to be successful had little to do with technology:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;New incentives to change required:&lt;/em&gt; Like many established product companies, the organization was structured around distinct, mature product lines. With very different P&amp;amp;Ls and incentives, we were told: “Careers are made within the business units, not the company.” There was an inherent skepticism for investing in unproven growth, especially if the effort was performed by a centralized function.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Lack of experience with data rights:&lt;/em&gt; At this time, a very small percentage of overall revenue was produced through software. To sidestep questions of license management, the default behavior was to “make stuff free so that we do not have to create licenses.”&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;New customer relationships (and approach to product development):&lt;/em&gt; Getting the most value from device data meant integrating it with some of the customers’ own data sources to provide greater context to end users. This meant expanding or revisiting customer relationships to embrace data sharing, requiring updates to processes in sales management (i.e., around channel or partnership agreements) and overarching application strategies (e.g., creating standards and cultivating ISV ecosystems).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In working together, we helped the industrial product company identify solutions for incentivizing technical investment. We identified policies required around data ownership, custody, and consent as a precursor to becoming an integrator and reseller in the supply chain of data services. We helped them update their architecture to support these services. It is not uncommon for an SVDS maturity assessment to reveal a broad set of opportunities.&lt;/p&gt;

&lt;p&gt;Ultimately, our client was equipped with a broader perspective on what they needed to launch their software business and a roadmap to build all aspects of their data capabilities, ensuring that their transformation would be more successful. A clear roadmap helped them fill in the gaps between here and there, illuminating the concrete steps they needed to achieve their vision. Although transformation does not have a fixed end point, milestones are important—change should be incremental enough that the organization can see progress.&lt;/p&gt;

&lt;p&gt;Although it won’t give you a full picture of your organization, these exercises are a good starting point to help you gain a better sense of your company’s data maturity and spark productive exchanges with your colleagues. Is your organization using data just for generating reports or focusing on use cases in mission-critical areas? Or is it putting data first in every business activity? Knowing where you stand will increase your understanding of your organization’s potential, provide a baseline for measuring progress, and give you a framework for thinking about your data operations and how they might compare with the competition’s and your industry’s as a whole.&lt;/p&gt;</content><author><name></name></author><summary type="html">First steps in a data strategy.</summary></entry><entry><title type="html">Digital Economy Part III: Technology requires deeper integration into our work lives.</title><link href="http://localhost:4000/digital-economy-part-3/" rel="alternate" type="text/html" title="Digital Economy Part III: Technology requires deeper integration into our work lives. " /><published>2017-06-23T00:00:00-07:00</published><updated>2017-06-23T00:00:00-07:00</updated><id>http://localhost:4000/digital-economy-part-3</id><content type="html" xml:base="http://localhost:4000/digital-economy-part-3/">&lt;p&gt;&lt;em&gt;These articles are part of exploration that started in late 2015 and early 2016. It was a confusing time: autonomous vehicles and Boston Dynamics were frequently in the news and OpenAI was just formed to make sure that the “march towards AGI was safe.” UBI was actively being discussed by Sam Altman and Ray Kurzweil was promoting 10x / exponential thinking. At the same time, economists like Robert Gordon were arguing that we were actually living in a time of low progress.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;I tried to develop my own perspective on what was happening, with key conclusions presented &lt;a href=&quot;https://bradaallen.github.io/digital-economy-intro/&quot;&gt;at this link&lt;/a&gt;. Greater detail supporting other conclusions can be found in &lt;a href=&quot;https://bradaallen.github.io/digital-economy-part-1/&quot;&gt;Part I&lt;/a&gt; and &lt;a href=&quot;https://bradaallen.github.io/digital-economy-part-2/&quot;&gt;Part II&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;

&lt;h3 id=&quot;labor-challenge-todays-digital-technologies-have-only-had-a-marginal-effect-on-worker-productivity&quot;&gt;Labor Challenge: Today’s digital technologies have only had a marginal effect on worker productivity.&lt;/h3&gt;

&lt;p&gt;Many of the consumer benefits from smartphones, Google searches, and Facebook do not lead to direct commercial growth in the economy: &lt;a href=&quot;https://www.brookings.edu/bpea-articles/does-the-united-states-have-a-productivity-slowdown-or-a-measurement-problem/&quot;&gt;consumers are now more productive in how they use their personal time&lt;/a&gt;. Likewise, many of the current advancements being made in CS today (e.g., natural language processing, computer vision) support discovery and search—that is, they primarily strengthen existing ICT value propositions for technology businesses. IT has not been as meaningful for what people do with their time at work as we might have hope.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;“The things at which Google and its peers excel, from Internet search to mobile software, are changing how we work, play and communicate, yet have had little discernible macroeconomic impact.…Transformative innovation really is happening on the Internet. It’s just not happening elsewhere.” 
– &lt;a href=&quot;https://www.wsj.com/articles/beyond-the-internet-innovation-struggles-1439401576&quot;&gt;Greg Ip, Wall Street Journal, August 12, 2015&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;For a macroeconomic perspective, McKinsey researchers recently examined 22 industries to measure “digital potential”— including both investment and the use of technology to change how work is done. Some industries, like technology, media and financial services, were well along, while others, like healthcare and hospitality, trailed. &lt;a href=&quot;http://www.nytimes.com/2016/06/06/business/why-the-economic-payoff-from-technology-is-so-elusive.html?mwrsm=Email&amp;amp;_r=0&quot;&gt;Only 18 percent of the American economy is living up to its “potential,”&lt;/a&gt; the report concluded. “…And if lagging industries do not catch up, we will not see much of a change in national economic statistics,” said James Manyika, a director of the McKinsey Global Institute.&lt;/p&gt;

&lt;p&gt;This concept of “digital potential” implies that the use of technology will provide new services and features that consumers value, and that corporations can provide at a profit over today’s operating models. Often, neither of these assumptions prove true:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;New technology isn’t implicitly better.&lt;/em&gt; Most new digitization efforts need to fit into the pre-existing user workflow to have a chance at adoption. Technology changes generally stick best when they have a &lt;a href=&quot;http://miter.mit.edu/articleentrepreneurship-technology-push-vs-market-pull/&quot;&gt;“pull mechanism”&lt;/a&gt;; as an example of this, interactive whiteboards (in 45% of schools in 2013) &lt;a href=&quot;https://www.edsurge.com/news/2013-10-22-lessons-from-the-downfall-of-interactive-whiteboards&quot;&gt;largely failed to be adopted by teachers&lt;/a&gt; even with significant investment from school administrators.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Half-efforts may fail and be worse than having done nothing at all.&lt;/em&gt; Many legacy businesses are required to completely rethink their operations to take advantage of digital opportunities — &lt;a href=&quot;http://www.vox.com/a/new-economy-future/technology-productivity&quot;&gt;companies need to be designed to solve these problems&lt;/a&gt;. This level of systems thinking is difficult to do: there are personnel problems, workflow problems, organizational problems, regulatory problems, amongst others. Taking advantage of IT in a company is really, really hard.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;what-does-it-all-mean&quot;&gt;What does it all mean&lt;/h3&gt;

&lt;p&gt;Of course, none of this is to say that digital transformation isn’t possible. Industries throughout the supply chain from factory to retailing have already been substantially reorganized to reduce inventory, waste, and headcount; and IT-supported efficiencies in middle management and administrative support have been exploited.&lt;/p&gt;

&lt;p&gt;“Needle-moving” changes require deep shifts in how businesses operate - for example, enabling experimentation, building internal software teams focused on removing “toil”, and Agile planning methodologies. These efforts often require a leap of faith from decision makers who have historically been successful without requiring any of those tools. It is a huge challenge to find the leadership, political will, and talent that can guide an organization through the pain of transformation.&lt;/p&gt;

&lt;p&gt;Additional research, perspective, and detail can be found in the following supporting articles:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://bradaallen.github.io/digital-economy-intro/&quot;&gt;Intro: Creating a general framework for current opportunities and challenges.&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://bradaallen.github.io/digital-economy-part-1/&quot;&gt;Part I: We are in a time of slow productivity and strong incumbents.&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://bradaallen.github.io/digital-economy-part-2/&quot;&gt;Part II: Aging &amp;amp; unproven learning models are headwinds to growth.&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;My goal in putting this together was to clarify my own thinking - and to present it in a way that can be challenged and deepened by others. I would be grateful to learn what may resonate (or differ) from your personal perspectives and work.&lt;/p&gt;</content><author><name></name></author><summary type="html">What's changed in our personal lives also needs to change in our 9-5s.</summary></entry><entry><title type="html">Digital Economy Part II: Aging &amp;amp; Unproven Learning Models are Headwinds to Growth.</title><link href="http://localhost:4000/digital-economy-part-2/" rel="alternate" type="text/html" title="Digital Economy Part II: Aging &amp; Unproven Learning Models are Headwinds to Growth." /><published>2017-06-06T00:00:00-07:00</published><updated>2017-06-06T00:00:00-07:00</updated><id>http://localhost:4000/digital-economy-part-2</id><content type="html" xml:base="http://localhost:4000/digital-economy-part-2/">&lt;p&gt;&lt;em&gt;These articles are part of exploration that started in late 2015 and early 2016. It was a confusing time: autonomous vehicles and Boston Dynamics were frequently in the news and OpenAI was just formed to make sure that the “march towards AGI was safe.” UBI was actively being discussed by Sam Altman and Ray Kurzweil was promoting 10x / exponential thinking. At the same time, economists like Robert Gordon were arguing that we were actually living in a time of low progress.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;I tried to develop my own perspective on what was happening, with key conclusions presented &lt;a href=&quot;https://bradaallen.github.io/digital-economy-intro/&quot;&gt;at this link&lt;/a&gt;. Greater detail supporting other conclusions can be found in &lt;a href=&quot;https://bradaallen.github.io/digital-economy-part-1/&quot;&gt;Part I&lt;/a&gt; and &lt;a href=&quot;https://bradaallen.github.io/digital-economy-part-3/&quot;&gt;Part III&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;

&lt;h3 id=&quot;aging-populations-are-an-increasing-share-of-the-overall-population-creating-challenges&quot;&gt;Aging populations are an increasing share of the overall population, creating challenges.&lt;/h3&gt;

&lt;p&gt;Noted in Part I, weak general innovation is one driver of low economic growth. Changes affecting the makeup of our labor force will provide &lt;a href=&quot;http://www.wsj.com/articles/for-economy-aging-population-poses-double-whammy-1470249965&quot;&gt;further drags on productivity&lt;/a&gt; Two factors are an aging labor force and a “skills challenge” for remaining labor attempting keeping up with dynamic changes in technology.&lt;/p&gt;

&lt;p&gt;Aging labor forces have a tremendous effect on productivity. On average, every 10% increase in the share of a state’s population over the age of 60 reduced per capita growth in gross domestic product by 5.5%. This is explained by two factors. First (and most intuitively), as more workers retire, the labor force grows more slowly. This explains one-third of the 5.5% growth hit. But the (surprising) bigger effect is through reduced productivity—that is, output per hour—of the remaining workers. Mentorship matters! Experienced employees make their less-experienced reports more productive.&lt;/p&gt;

&lt;p&gt;This effect of aging on productivity will be even more pronounced as McKinsey estimates that we are entering an era of &lt;a href=&quot;http://www.mckinsey.com/global-themes/employment-and-growth/the-world-at-work&quot;&gt;slow-growing or even shrinking labor forces (see image below)&lt;/a&gt;. To maintain historical rates of GDP growth, it’s estimated that the “aging advanced” economies would need to increase productivity growth by about 60 percent of historical levels, to about 1.9 percent annually. This is a rate that hasn’t been reached since the 1960s. As an extreme example, the Southern Europe cluster will face an even steeper challenge: these economies would need to double their 0.7 percent rate of productivity growth of the past 20 years to sustain growth in GDP per capita.&lt;/p&gt;

&lt;figure&gt;
	&lt;img src=&quot;/images/mckinsey_aging_productivity.PNG&quot; /&gt;
&lt;/figure&gt;

&lt;p&gt;When these productivity challenges are coupled with declining labor force participation rates, the ultimate effect is a deceleration in per capita GDP growth. Future generations could have a lower rate of improvement in living standards than their parents—and in some cases, such as in the Southern Europe cluster, the next generation could be poorer than their parents.&lt;/p&gt;

&lt;h3 id=&quot;for-younger-workers-capturing-emerging-areas-of-economic-growth-require-new-skills&quot;&gt;For younger workers, capturing emerging areas of economic growth require new skills.&lt;/h3&gt;

&lt;p&gt;What about the remaining labor force? Here we find significant mismatches between what employees can do and what firms need to be done. In most advanced economies, unemployment rates for the least-skilled are two to four times those of the most highly skilled workers, whether the economy is in recession or recovery. The effects of falling demand for low-skill labor have been especially harsh for younger workers. Today, 75 million young people (aged 15 to 24) who are not in school or college are unemployed, account for 38 percent of the world’s unemployed.&lt;/p&gt;

&lt;p&gt;For skilled labor, firms are finding a lack of talent—a “STEM shortage.” This is reflected in the time required to fill roles. &lt;a href=&quot;https://www.brookings.edu/interactives/still-searching-job-vacancies-and-stem-skills/&quot;&gt;In a Brookings study&lt;/a&gt;, the duration of advertising for a STEM occupation that typically requires a graduate degree is 25 days at the median, 50 days average, and 93 days at the 80th percentile. These search times are much longer than the average for all non-STEM U.S. vacancies, for which the median is just five days, the average is 33, and the 80th percentile is 64. The question of how to tackle these problems—adapting an economy with a large aging population with significant dynamism in the most valued skills—will be a challenge of the next few decades.&lt;/p&gt;

&lt;h3 id=&quot;skills-in-digital-growth-will-require-new-education-models-that-are-promising-but-unproven&quot;&gt;Skills in digital growth will require new education models that are promising, but unproven.&lt;/h3&gt;

&lt;p&gt;There has been much documentation around occupational skill gaps: for example, &lt;a href=&quot;http://www.themanufacturinginstitute.org/Research/Skills-Gap-in-Manufacturing/Skills-Gap-in-Manufacturing.aspx&quot;&gt;in manufacturing&lt;/a&gt;, &lt;a href=&quot;http://www.bls.gov/opub/mlr/2015/article/stem-crisis-or-stem-surplus-yes-and-yes.htm&quot;&gt;in STEM&lt;/a&gt;, and in digital literacy. As a result, many non-traditional workforce development programs have been created in recent years, including online courses (MOOCs) and bootcamp models. Tech training is touted by workforce development policymakers as being at the leading edge of trends such as skills-based hiring, non-traditional learning, and rapid education models. Bootcamps are considered by some to be at the forefront of workforce development more generally.&lt;/p&gt;

&lt;p&gt;Yet the field is new, and the lack of comprehensive and concrete data on outcomes and transparency makes much of the tech training hype difficult to verify. Additionally, &lt;a href=&quot;https://www.jpmorganchase.com/corporate/Corporate-Responsibility/document/JPMC-tech-training-report-web.pdf&quot;&gt;policymakers and employers may be overwhelmed&lt;/a&gt; by the abundance of new training programs. Questions still linger about whether these programs are successfully creating a skilled tech workforce that meets employers’ needs, much less if these programs are fulfilling the promise of economic mobility for participants and creating a workforce that is diverse in gender and race.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;“The rubber hits the road at employment. All this great stuff means nothing if you don’t hire the people at the end.” – Barbara Chang, Code to Work&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;As a relatively new field, complete data does not exist to evaluate which programs are most effective, making it difficult for employers, participants, and funders to determine their success. The data most programs release do not show whether graduates take jobs in the field, or whether they are still employed several years later. As a result, employers may be missing good job candidates due to limited resources for recruitment and job seekers must rely on anecdotes and unverified statistics to make decisions about whether to participate in a program and which one to choose.&lt;/p&gt;

&lt;h3 id=&quot;what-does-it-all-mean&quot;&gt;What does it all mean&lt;/h3&gt;

&lt;p&gt;Aging populations may be a significant headwind to growth in the subsequent decades. To maintain and exceed current rates of productivity growth, the population will need to more intensively adopt digital skills. Job skills, retraining, and effective certification are particularly important areas of public-private partnerships.&lt;/p&gt;

&lt;p&gt;Additional research, perspective, and detail can be found in the following supporting articles:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://bradaallen.github.io/digital-economy-intro/&quot;&gt;Intro: Creating a general framework for current opportunities and challenges.&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://bradaallen.github.io/digital-economy-part-1/&quot;&gt;Part I: We are in a time of slow productivity and strong incumbents.&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://bradaallen.github.io/digital-economy-part-3/&quot;&gt;Part III: Technology requires deeper integration into our work lives.&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;My goal in putting this together was to clarify my own thinking - and to present it in a way that can be challenged and deepened by others. I would be grateful to learn what may resonate (or differ) from your personal perspectives and work.&lt;/p&gt;</content><author><name></name></author><summary type="html">Demographic and structural barriers to progress exist.</summary></entry></feed>